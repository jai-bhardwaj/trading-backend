"""
Redis-Based Trading Engine

High-performance trading engine using Redis queues for order processing.
Replaces the database polling approach with real-time queue processing.
"""

import asyncio
import logging
import signal
import sys
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
from sqlalchemy.orm import Session
from sqlalchemy import select

from app.database import DatabaseManager
from app.models.base import Order, OrderStatus, Strategy, StrategyStatus, User, BrokerConfig, OrderSide, OrderType, ProductType
from app.queue import QueueManager, WorkerConfig, QueueConfig, QueuedOrder, PriorityOrderMetadata
from app.queue.priority_queue import OrderUrgency
from app.brokers import get_broker_instance
from app.strategies import AutomaticStrategyRegistry  # Import from strategies module, not registry directly
from app.core.instrument_manager import get_instrument_manager
from app.utils.timezone_utils import ist_utcnow as datetime_now

logger = logging.getLogger(__name__)

class RedisBasedTradingEngine:
    """
    High-performance trading engine using Redis queues for order processing.
    
    Key improvements over database polling:
    - Real-time order processing (no polling delay)
    - Horizontal scalability with multiple workers
    - Priority-based order routing
    - Automatic retry with exponential backoff
    - Circuit breaker pattern for fault tolerance
    - Comprehensive monitoring and health checks
    """
    
    def __init__(self, worker_count: int = 4, max_queue_size: int = 10000, db_manager=None):
        # Use provided database manager or get global instance
        if db_manager:
            self.db_manager = db_manager
        else:
            from app.database import get_database_manager
            self.db_manager = get_database_manager()
        
        # Queue configuration
        self.worker_config = WorkerConfig(
            worker_count=worker_count,
            enable_priority_processing=True,
            enable_load_balancing=True,
            health_check_interval=30
        )
        
        self.queue_config = QueueConfig(
            queue_name="trading_orders",
            priority_queue_name="priority_orders",
            enable_retry_processing=True,
            enable_queue_rebalancing=True,
            max_queue_size=max_queue_size
        )
        
        # Initialize queue manager
        self.queue_manager = QueueManager(self.worker_config, self.queue_config, self.db_manager)
        
        # Engine state
        self.is_running = False
        self.start_time = datetime_now()
        
        # Strategy management
        self.active_strategies: Dict[str, Any] = {}
        self.strategy_last_run: Dict[str, datetime] = {}
        
        # Performance metrics
        self.orders_processed = 0
        self.orders_failed = 0
        self.strategies_executed = 0
        
        # Background tasks
        self.background_tasks: List[asyncio.Task] = []
        
        # Setup signal handlers
        self._setup_signal_handlers()
    
    async def start(self):
        """Start the Redis-based trading engine"""
        if self.is_running:
            logger.warning("‚ö†Ô∏è Trading engine is already running")
            return
        
        logger.info("üöÄ Starting Redis-Based Trading Engine")
        self.is_running = True
        self.start_time = datetime_now()
        
        try:
            # Initialize strategy registry first
            logger.info("üìã Initializing strategy registry...")
            from app.strategies import initialize_strategies
            initialize_strategies(force_reload=True)
            
            # Verify strategies are loaded
            available_strategies = AutomaticStrategyRegistry.list_strategies()
            logger.info(f"üìà Available strategies: {available_strategies}")
            
            # Test specific strategy lookup
            test_strategy = AutomaticStrategyRegistry.get_strategy_class('RealtimeTestStrategy')
            logger.info(f"üîç RealtimeTestStrategy lookup result: {test_strategy}")
            
            if not available_strategies:
                logger.warning("‚ö†Ô∏è No strategies found in registry, attempting direct initialization...")
                AutomaticStrategyRegistry.initialize(auto_discover=True)
                available_strategies = AutomaticStrategyRegistry.list_strategies()
                logger.info(f"üìà After direct init: {available_strategies}")
            
            # Start queue manager
            if not self.queue_manager.start():
                logger.error("‚ùå Failed to start queue manager")
                return False
            
            # Load active strategies
            await self._load_active_strategies()
            
            # Start background tasks
            await self._start_background_tasks()
            
            logger.info("‚úÖ Redis-Based Trading Engine started successfully")
            logger.info(f"üìä Configuration: {self.worker_config.worker_count} workers, max queue size: {self.queue_config.max_queue_size}")
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Failed to start trading engine: {e}")
            await self.stop()
            return False
    
    async def stop(self):
        """Stop the trading engine gracefully"""
        if not self.is_running:
            logger.warning("‚ö†Ô∏è Trading engine is not running")
            return
        
        logger.info("‚èπÔ∏è Stopping Redis-Based Trading Engine...")
        self.is_running = False
        
        # Stop background tasks
        await self._stop_background_tasks()
        
        # Stop queue manager
        self.queue_manager.stop()
        
        # Calculate uptime
        if self.start_time:
            uptime = datetime_now() - self.start_time
            logger.info(f"üìä Engine uptime: {uptime}")
            logger.info(f"üìä Orders processed: {self.orders_processed}")
            logger.info(f"üìä Orders failed: {self.orders_failed}")
            logger.info(f"üìä Strategies executed: {self.strategies_executed}")
        
        logger.info("üèÅ Redis-Based Trading Engine stopped")
    
    async def submit_order(self, order_id: str, priority: int = 2, urgency: str = OrderUrgency.NORMAL.value) -> bool:
        """Submit an order to the Redis queue for processing"""
        try:
            async with self.db_manager.get_async_session() as db:
                # Get order from database
                order = await db.get(Order, order_id)
                if not order:
                    logger.error(f"‚ùå Order {order_id} not found in database")
                    return False
                
                # Create queued order
                queued_order = QueuedOrder(
                    order_id=order.id,
                    user_id=order.user_id,
                    symbol=order.symbol,
                    side=order.side.value,
                    order_type=order.order_type.value,
                    quantity=order.quantity,
                    price=order.price,
                    priority=priority,
                    metadata={
                        'strategy_id': order.strategy_id,
                        'exchange': order.exchange,
                        'product_type': order.product_type.value if order.product_type else 'INTRADAY'
                    }
                )
                
                # Create priority metadata if high priority
                priority_metadata = None
                if priority >= 3 or urgency != OrderUrgency.NORMAL.value:
                    priority_metadata = PriorityOrderMetadata(
                        urgency=urgency,
                        strategy_id=order.strategy_id,
                        risk_level="MEDIUM" if priority >= 4 else "LOW"
                    )
                
                # Submit to queue
                success = self.queue_manager.enqueue_order(queued_order, priority_metadata)
                
                if success:
                    # Update order status in database
                    order.status = OrderStatus.QUEUED
                    await db.commit()
                    
                    logger.info(f"üì§ Order {order_id} submitted to queue (priority: {priority}, urgency: {urgency})")
                else:
                    logger.error(f"‚ùå Failed to submit order {order_id} to queue")
                
                return success
            
        except Exception as e:
            logger.error(f"‚ùå Error submitting order {order_id}: {e}")
            return False
    
    async def submit_urgent_order(self, order_id: str, urgency: str = OrderUrgency.STOP_LOSS.value, deadline: Optional[datetime] = None) -> bool:
        """Submit an urgent order with high priority"""
        try:
            async with self.db_manager.get_async_session() as db:
                order = await db.get(Order, order_id)
                if not order:
                    logger.error(f"‚ùå Order {order_id} not found")
                    return False
                
                # Create high-priority queued order
                queued_order = QueuedOrder(
                    order_id=order.id,
                    user_id=order.user_id,
                    symbol=order.symbol,
                    side=order.side.value,
                    order_type=order.order_type.value,
                    quantity=order.quantity,
                    price=order.price,
                    priority=5,  # Critical priority
                    metadata={
                        'strategy_id': order.strategy_id,
                        'exchange': order.exchange,
                        'product_type': order.product_type.value if order.product_type else 'INTRADAY',
                        'urgent': True
                    }
                )
                
                # Create urgent priority metadata
                priority_metadata = PriorityOrderMetadata(
                    urgency=urgency,
                    deadline=deadline.isoformat() if deadline else None,
                    strategy_id=order.strategy_id,
                    risk_level="HIGH"
                )
                
                # Submit to priority queue
                success = self.queue_manager.enqueue_order(queued_order, priority_metadata)
                
                if success:
                    order.status = OrderStatus.QUEUED
                    await db.commit()
                    
                    logger.info(f"üö® Urgent order {order_id} submitted (urgency: {urgency})")
                
                return success
            
        except Exception as e:
            logger.error(f"‚ùå Error submitting urgent order {order_id}: {e}")
            return False
    
    async def _load_active_strategies(self):
        """Load active strategies from database"""
        try:
            async with self.db_manager.get_async_session() as db:
                # Get active strategies
                result = await db.execute(
                    select(Strategy).where(
                        Strategy.status == StrategyStatus.ACTIVE
                    )
                )
                strategies = result.scalars().all()
                for strategy in strategies:
                    self.active_strategies[strategy.id] = {
                        'strategy': strategy,
                        'last_execution': None,
                        'execution_count': 0,
                        'error_count': 0
                    }
                    logger.info(f"üìà Loaded active strategy: {strategy.name} ({strategy.strategy_type})")
                logger.info(f"‚úÖ Loaded {len(self.active_strategies)} active strategies")
        except Exception as e:
            logger.error(f"‚ùå Error loading active strategies: {e}")
    
    async def _start_background_tasks(self):
        """Start background tasks"""
        # Strategy execution task
        task = asyncio.create_task(self._strategy_executor())
        self.background_tasks.append(task)
        
        # Database sync task
        task = asyncio.create_task(self._database_sync())
        self.background_tasks.append(task)
        
        # Performance monitoring task
        task = asyncio.create_task(self._performance_monitor())
        self.background_tasks.append(task)
        
        # Queue health monitor
        task = asyncio.create_task(self._queue_health_monitor())
        self.background_tasks.append(task)
        
        logger.info(f"üîÑ Started {len(self.background_tasks)} background tasks")
    
    async def _stop_background_tasks(self):
        """Stop all background tasks"""
        for task in self.background_tasks:
            task.cancel()
        
        # Wait for tasks to complete
        if self.background_tasks:
            await asyncio.gather(*self.background_tasks, return_exceptions=True)
        
        self.background_tasks.clear()
        logger.info("üèÅ Background tasks stopped")
    
    async def _strategy_executor(self):
        """Execute active strategies periodically"""
        while self.is_running:
            try:
                for strategy_id, strategy_data in self.active_strategies.items():
                    try:
                        strategy = strategy_data['strategy']
                        
                        # Check if strategy should run based on timeframe
                        if self._should_execute_strategy(strategy_id, strategy.timeframe):
                            await self._execute_strategy(strategy_id, strategy)
                            self.strategies_executed += 1
                    
                    except Exception as e:
                        logger.error(f"‚ùå Error executing strategy {strategy_id}: {e}")
                        strategy_data['error_count'] += 1
                
                # Wait before next execution cycle
                await asyncio.sleep(30)  # Check every 30 seconds
                
            except Exception as e:
                logger.error(f"‚ùå Strategy executor error: {e}")
                await asyncio.sleep(60)
    
    async def _execute_strategy(self, strategy_id: str, strategy: Strategy):
        """Execute a single strategy"""
        try:
            # Get or create strategy instance
            strategy_instance = self.active_strategies[strategy_id].get('instance')
            
            if not strategy_instance:
                # Create strategy instance for the first time
                strategy_class = AutomaticStrategyRegistry.get_strategy_class(strategy.strategy_type)
                if not strategy_class:
                    logger.error(f"‚ùå Strategy type {strategy.strategy_type} not found in registry")
                    return
                
                # Get symbols from instrument manager based on strategy asset class
                instrument_manager = await get_instrument_manager(self.db_manager)
                
                # Get symbols for this strategy's asset class
                strategy_symbols = instrument_manager.get_all_symbols(strategy.asset_class)
                if not strategy_symbols:
                    strategy_symbols = strategy.symbols or ["RELIANCE", "TCS", "INFY"]  # Fallback
                else:
                    strategy_symbols = strategy_symbols[:10]  # Limit symbols per strategy
                
                # Create strategy instance
                from app.models.base import AssetClass
                
                # Convert TimeFrame enum using strings for now (simplified approach)
                timeframe_mapping = {
                    "MINUTE_1": "MINUTE_1",
                    "MINUTE_5": "MINUTE_5", 
                    "MINUTE_15": "MINUTE_15",
                    "HOUR_1": "HOUR_1",
                    "HOUR_4": "HOUR_4",
                    "DAY_1": "DAY_1",
                    "WEEK_1": "WEEK_1"
                }
                
                strategy_timeframe = timeframe_mapping.get(strategy.timeframe.value, "MINUTE_5")
                
                # Create strategy config for the BaseStrategy
                config = {
                    'name': strategy.name,
                    'asset_class': strategy.asset_class.value,
                    'symbols': strategy_symbols,
                    'timeframe': strategy_timeframe,
                    'parameters': strategy.parameters or {},
                    'risk_parameters': strategy.risk_parameters or {},
                    'is_active': True,
                    'paper_trade': False,
                    'execution_interval': 5,
                    'capital_allocated': 100000,
                    'max_positions': 5,
                    'risk_per_trade': 0.02
                }
                
                # Create strategy instance with correct parameters
                strategy_instance = strategy_class(
                    config_id=strategy.id,
                    user_id=strategy.user_id,
                    strategy_id=strategy.id,
                    config=config
                )
                
                # Initialize the strategy
                await strategy_instance.initialize()
                
                # Store strategy instance for reuse
                self.active_strategies[strategy_id]['instance'] = strategy_instance
                logger.info(f"‚úÖ Created and cached strategy instance: {strategy.name}")
            
            # Process each symbol using the cached strategy instance
            # Get symbols from database Strategy model, not strategy instance
            strategy_symbols = strategy.symbols or ["RELIANCE", "TCS", "INFY"]  # Fallback symbols
            logger.info(f"üîÑ Executing strategy {strategy.name} for symbols: {strategy_symbols}")
            
            for symbol in strategy_symbols:
                # Get market data
                market_data = await self._get_market_data(symbol, strategy.timeframe)
                
                if market_data:
                    logger.info(f"üìä Generated market data for {symbol}: price={market_data['close']}")
                    # Process market data and get signal
                    signal = await strategy_instance.process_market_data(market_data)
                    
                    if signal:
                        # Create order from signal
                        await self._create_order_from_signal(strategy, signal)
                        logger.info(f"üéØ Strategy {strategy.name} generated signal for {symbol}: {signal.get('type', 'UNKNOWN')}")
                    else:
                        logger.debug(f"üìä No signal generated for {symbol}")
                else:
                    logger.warning(f"‚ùå Failed to generate market data for {symbol}")
            
            # Update strategy execution time
            self.active_strategies[strategy_id]['last_execution'] = datetime_now()
            self.active_strategies[strategy_id]['execution_count'] += 1
            
        except Exception as e:
            logger.error(f"‚ùå Error executing strategy {strategy_id}: {e}")
            self.active_strategies[strategy_id]['error_count'] += 1
    
    def _should_execute_strategy(self, strategy_id: str, timeframe) -> bool:
        """Check if strategy should be executed based on timeframe"""
        last_execution = self.active_strategies[strategy_id]['last_execution']
        
        if not last_execution:
            return True
        
        # Define timeframe intervals
        intervals = {
            'MINUTE_1': timedelta(minutes=1),
            'MINUTE_5': timedelta(minutes=5),
            'MINUTE_15': timedelta(minutes=15),
            'HOUR_1': timedelta(hours=1),
            'DAY_1': timedelta(days=1)
        }
        
        interval = intervals.get(timeframe.value, timedelta(minutes=5))
        return datetime_now() - last_execution >= interval
    
    async def _get_market_data(self, symbol: str, timeframe):
        """Get market data with simulated data (live broker disabled for stability)"""
        try:
            # For now, use simulated data to ensure system stability
            # Live broker integration can be enabled later once all issues are resolved
            logger.debug(f"üìä Generating simulated market data for {symbol}")
            
            # Note: Live broker integration is temporarily disabled to avoid session binding issues
            # This will be re-enabled once the broker authentication system is fully stabilized
            
            # Fallback to simulated data if live data fails
            import random
            
            # Get base price for symbol
            base_prices = {
                'RELIANCE': 2500.0,
                'TCS': 3800.0,
                'INFY': 1800.0,
                'HDFC': 1600.0,
                'TATAMOTORS': 900.0,
                'BAJFINANCE': 7000.0,
                'MARUTI': 11000.0
            }
            
            base_price = base_prices.get(symbol, 1000.0)
            
            # Generate realistic market data
            change_pct = random.uniform(-0.02, 0.02)  # ¬±2% change
            current_price = base_price * (1 + change_pct)
            
            # Generate OHLC data
            high = current_price * random.uniform(1.001, 1.005)
            low = current_price * random.uniform(0.995, 0.999)
            volume = random.randint(100000, 1000000)
            
            market_data = {
                'symbol': symbol,
                'timestamp': datetime_now(),
                'open': base_price,
                'high': high,
                'low': low,
                'close': current_price,
                'ltp': current_price,  # Last traded price
                'volume': volume,
                'asset_class': 'EQUITY',
                'exchange': "NSE",
                'change': current_price - base_price,
                'change_pct': change_pct * 100,
                'previous_close': base_price,
                'source': 'simulated_fallback'
            }
            
            logger.debug(f"üìä Simulated market data for {symbol}: ‚Çπ{current_price}")
            return market_data
            
        except Exception as e:
            logger.error(f"Error getting market data for {symbol}: {e}")
            return None
    
    async def _create_order_from_signal(self, strategy: Strategy, signal):
        """Create order from strategy signal"""
        try:
                        
            async with self.db_manager.get_async_session() as db:
                # Determine order side based on signal type
                signal_type = signal.get('type', '').upper()
                if signal_type == 'BUY':
                    order_side = OrderSide.BUY
                elif signal_type == 'SELL':
                    order_side = OrderSide.SELL
                else:
                    logger.warning(f"Unknown signal type: {signal_type}")
                    return False
                
                # Create new order
                order = Order(
                    user_id=strategy.user_id,
                    strategy_id=strategy.id,
                    symbol=signal.get('symbol', 'UNKNOWN'),
                    exchange=signal.get('exchange', 'NSE'),  # Default exchange
                    side=order_side,
                    order_type=OrderType.MARKET,  # Default to market orders
                    product_type=ProductType.INTRADAY,  # Default product type
                    quantity=signal.get('quantity', 1),
                    price=signal.get('price', 0.0),
                    status=OrderStatus.PENDING,
                    notes=f"Generated by strategy: {strategy.name} with {signal.get('confidence', 0.5):.1%} confidence"
                )
                
                db.add(order)
                await db.commit()
                await db.refresh(order)
                
                # Submit order to queue
                priority = 3 if signal.get('confidence', 0.5) > 0.8 else 2
                await self.submit_order(order.id, priority=priority)
                
                logger.info(f"üìà Created order from strategy signal: {signal.get('symbol')} {signal_type} {signal.get('quantity')} (Confidence: {signal.get('confidence', 0.5):.1%})")
                
                return True
            
        except Exception as e:
            logger.error(f"‚ùå Error creating order from signal: {e}")
            return False
    
    async def _database_sync(self):
        """Sync pending orders from database to queue"""
        while self.is_running:
            try:
                async with self.db_manager.get_async_session() as db:
                    # Get pending orders that are not yet queued
                    pending_orders = await db.execute(
                        select(Order).where(
                            Order.status == OrderStatus.PENDING
                        )
                    )
                    pending_orders = pending_orders.scalars().all()
                    
                    for order in pending_orders:
                        await self.submit_order(order.id)
                    
                    if pending_orders:
                        logger.info(f"üì§ Synced {len(pending_orders)} pending orders to queue")
                
                # Wait before next sync
                await asyncio.sleep(60)  # Sync every minute
                
            except Exception as e:
                logger.error(f"‚ùå Database sync error: {e}")
                await asyncio.sleep(120)  # Wait longer on error
    
    async def _performance_monitor(self):
        """Monitor engine performance"""
        while self.is_running:
            try:
                # Get queue statistics
                stats = self.queue_manager.get_comprehensive_stats()
                
                # Log performance metrics
                if stats and 'queue_summary' in stats:
                    summary = stats['queue_summary']
                    logger.info(f"üìä Queue Status - Pending: {summary.get('total_pending', 0)}, "
                              f"Processing: {summary.get('total_processing', 0)}, "
                              f"Failed: {summary.get('total_failed', 0)}")
                
                # Log worker performance
                if stats and 'workers' in stats:
                    workers = stats['workers']
                    logger.info(f"üë• Workers - Processed: {workers.get('total_processed', 0)}, "
                              f"Errors: {workers.get('total_errors', 0)}, "
                              f"Success Rate: {workers.get('overall_success_rate', 0):.2%}")
                
                await asyncio.sleep(300)  # Report every 5 minutes
                
            except Exception as e:
                logger.error(f"‚ùå Performance monitor error: {e}")
                await asyncio.sleep(300)
    
    async def _queue_health_monitor(self):
        """Monitor queue health and take corrective actions"""
        while self.is_running:
            try:
                stats = self.queue_manager.get_comprehensive_stats()
                
                if stats and 'health' in stats:
                    health = stats['health']
                    
                    if health.get('status') == 'critical':
                        logger.warning(f"üö® Queue health critical: {health.get('issues', [])}")
                        
                        # Take corrective actions
                        await self._handle_critical_health(health)
                    
                    elif health.get('status') == 'warning':
                        logger.warning(f"‚ö†Ô∏è Queue health warning: {health.get('issues', [])}")
                
                await asyncio.sleep(60)  # Check every minute
                
            except Exception as e:
                logger.error(f"‚ùå Queue health monitor error: {e}")
                await asyncio.sleep(120)
    
    async def _handle_critical_health(self, health: dict):
        """Handle critical health issues"""
        issues = health.get('issues', [])
        
        for issue in issues:
            if "Queue near capacity" in issue:
                logger.warning("üö® Queue near capacity - implementing emergency measures")
                # Could implement emergency queue clearing or worker scaling
            
            elif "Inactive workers" in issue:
                logger.warning("üö® Inactive workers detected - attempting restart")
                # Could restart inactive workers
            
            elif "High error rate" in issue:
                logger.warning("üö® High error rate detected - investigating")
                # Could implement error analysis and mitigation
    
    def _setup_signal_handlers(self):
        """Setup signal handlers for graceful shutdown"""
        def signal_handler(signum, frame):
            logger.info(f"üì° Received signal {signum}, initiating graceful shutdown...")
            asyncio.create_task(self.stop())
        
        signal.signal(signal.SIGINT, signal_handler)
        signal.signal(signal.SIGTERM, signal_handler)
    
    def get_engine_stats(self) -> Dict[str, Any]:
        """Get comprehensive engine statistics"""
        uptime_seconds = (datetime_now() - self.start_time).total_seconds()
        
        queue_stats = self.queue_manager.get_comprehensive_stats()
        
        return {
            'engine': {
                'is_running': self.is_running,
                'uptime_seconds': uptime_seconds,
                'orders_processed': self.orders_processed,
                'orders_failed': self.orders_failed,
                'strategies_executed': self.strategies_executed,
                'active_strategies': len(self.active_strategies),
                'background_tasks': len(self.background_tasks)
            },
            'queue_manager': queue_stats,
            'strategies': {
                strategy_id: {
                    'name': data['strategy'].name,
                    'type': data['strategy'].strategy_type,
                    'last_execution': data['last_execution'].isoformat() if data['last_execution'] else None,
                    'execution_count': data['execution_count'],
                    'error_count': data['error_count']
                }
                for strategy_id, data in self.active_strategies.items()
            }
        }

    async def process_orders(self):
        """Trigger a single round of order processing (simulate worker)."""
        # This system is designed for background processing, but for on-demand:
        # You could trigger a worker to process one order, or log the current queue state.
        stats = self.queue_manager.get_comprehensive_stats()
        logger.info(f"[process_orders] Queue stats: {stats.get('queue_summary', {})}")
        # Real order processing is handled by background workers.

    async def execute_active_strategies(self):
        """Run one round of strategy execution for all active strategies."""
        for strategy_id, strategy_data in self.active_strategies.items():
            try:
                strategy = strategy_data['strategy']
                if self._should_execute_strategy(strategy_id, strategy.timeframe):
                    await self._execute_strategy(strategy_id, strategy)
                    self.strategies_executed += 1
            except Exception as e:
                logger.error(f"[execute_active_strategies] Error executing strategy {strategy_id}: {e}")
                strategy_data['error_count'] += 1

    async def update_market_data(self):
        """Fetch and log market data for all tracked symbols (placeholder)."""
        symbols = set()
        for strategy_data in self.active_strategies.values():
            strategy = strategy_data['strategy']
            # Get symbols from database Strategy model, with fallback
            strategy_symbols = strategy.symbols or ["RELIANCE", "TCS", "INFY"]
            symbols.update(strategy_symbols)
        for symbol in symbols:
            data = await self._get_market_data(symbol, None)
            logger.info(f"[update_market_data] Market data for {symbol}: {data}")

    async def monitor_performance(self):
        """Log current performance metrics (single call, not a loop)."""
        stats = self.queue_manager.get_comprehensive_stats()
        if stats and 'queue_summary' in stats:
            summary = stats['queue_summary']
            logger.info(f"[monitor_performance] Queue Status - Pending: {summary.get('total_pending', 0)}, Processing: {summary.get('total_processing', 0)}, Failed: {summary.get('total_failed', 0)}")
        if stats and 'workers' in stats:
            workers = stats['workers']
            logger.info(f"[monitor_performance] Workers - Processed: {workers.get('total_processed', 0)}, Errors: {workers.get('total_errors', 0)}, Success Rate: {workers.get('overall_success_rate', 0):.2%}")

    async def perform_risk_checks(self):
        """Run a single risk/health check on the queue."""
        stats = self.queue_manager.get_comprehensive_stats()
        if stats and 'health' in stats:
            health = stats['health']
            logger.info(f"[perform_risk_checks] Queue health: {health}")
            if health.get('status') == 'critical':
                await self._handle_critical_health(health)

    async def health_check(self) -> Dict[str, Any]:
        """
        Comprehensive health check for the trading engine
        
        Returns:
            Dict containing health status and metrics
        """
        health = {
            "engine_running": self.is_running,
            "workers_healthy": True,
            "queue_healthy": True,
            "database_healthy": False,
            "redis_healthy": False,
            "overall_healthy": False,
            "errors": []
        }
        
        try:
            # Check database health through db_manager
            if self.db_manager:
                db_health = await self.db_manager.health_check()
                health["database_healthy"] = db_health.get("database", {}).get("healthy", False)
                health["redis_healthy"] = db_health.get("redis", {}).get("healthy", False)
            
            # Check queue manager health
            if self.queue_manager:
                try:
                    queue_health = await self.queue_manager.health_check()
                    health["queue_healthy"] = queue_health.get("healthy", False)
                except Exception as e:
                    health["queue_healthy"] = False
                    health["errors"].append(f"Queue health check failed: {e}")
            
            # Check worker status
            try:
                workers_status = await self.queue_manager.get_worker_status()
                healthy_workers = sum(1 for status in workers_status.values() if status == "running")
                total_workers = len(workers_status)
                health["workers_healthy"] = healthy_workers == total_workers
                health["worker_details"] = {
                    "healthy": healthy_workers,
                    "total": total_workers,
                    "status": workers_status
                }
            except Exception as e:
                health["workers_healthy"] = False
                health["errors"].append(f"Worker status check failed: {e}")
            
            # Overall health
            health["overall_healthy"] = (
                health["engine_running"] and
                health["workers_healthy"] and
                health["queue_healthy"] and
                health["database_healthy"] and
                health["redis_healthy"]
            )
            
        except Exception as e:
            health["errors"].append(f"Health check error: {e}")
            logger.error(f"‚ùå Health check failed: {e}")
        
        return health
    
    async def get_performance_metrics(self) -> Dict[str, Any]:
        """
        Get comprehensive performance metrics for the trading engine
        
        Returns:
            Dict containing performance metrics
        """
        uptime = (datetime_now() - self.start_time).total_seconds() if self.start_time else 0
        
        metrics = {
            "orders_processed": self.orders_processed,
            "orders_failed": self.orders_failed,
            "strategies_executed": self.strategies_executed,
            "uptime_seconds": uptime,
            "queue_size": 0,
            "worker_status": {},
            "engine_running": self.is_running,
            "active_strategies": len(self.active_strategies),
            "success_rate": 0.0,
            "processing_rate": 0.0
        }
        
        try:
            # Get queue metrics
            if self.queue_manager:
                queue_metrics = await self.queue_manager.get_performance_metrics()
                metrics.update({
                    "queue_size": queue_metrics.get("pending_orders", 0),
                    "queue_metrics": queue_metrics
                })
            
            # Get worker status
            try:
                worker_status = await self.queue_manager.get_worker_status()
                metrics["worker_status"] = worker_status
            except Exception as e:
                logger.debug(f"Could not get worker status: {e}")
                metrics["worker_status"] = {"error": str(e)}
            
            # Calculate success rate
            total_orders = self.orders_processed + self.orders_failed
            if total_orders > 0:
                metrics["success_rate"] = (self.orders_processed / total_orders) * 100
            
            # Calculate processing rate (orders per minute)
            if uptime > 0:
                metrics["processing_rate"] = (total_orders / uptime) * 60
            
            # Add strategy execution metrics
            metrics["strategy_metrics"] = {
                "total_strategies": len(self.active_strategies),
                "last_execution_times": dict(self.strategy_last_run)
            }
            
        except Exception as e:
            logger.error(f"‚ùå Error getting performance metrics: {e}")
            metrics["error"] = str(e)
        
        return metrics

# Main entry point for the Redis-based engine
async def main():
    """Main entry point for the Redis-based trading engine"""
    engine = RedisBasedTradingEngine(worker_count=4, max_queue_size=10000)
    
    try:
        # Start the engine
        if await engine.start():
            logger.info("üöÄ Redis-Based Trading Engine is running")
            
            # Keep running until interrupted
            while engine.is_running:
                await asyncio.sleep(1)
        else:
            logger.error("‚ùå Failed to start trading engine")
            sys.exit(1)
    
    except KeyboardInterrupt:
        logger.info("‚èπÔ∏è Shutdown requested by user")
    except Exception as e:
        logger.error(f"‚ùå Unexpected error: {e}")
    finally:
        await engine.stop()

if __name__ == "__main__":
    # Configure logging
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # Run the engine
    asyncio.run(main())

# Alias for compatibility
RedisEngine = RedisBasedTradingEngine 